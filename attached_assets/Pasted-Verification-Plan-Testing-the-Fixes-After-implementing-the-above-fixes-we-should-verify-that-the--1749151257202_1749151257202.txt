Verification Plan (Testing the Fixes)
After implementing the above fixes, we should verify that the rankings output is corrected. Key things to test:
* No FCS Teams in Data: Run the teams fetch for the season and confirm the count equals the known FBS team count (e.g. 134 for 2024)GitHub. Similarly, ensure the games dataset contains only FBS vs FBS matchups (the total games for a full season should be in line with historical totals, roughly 800+ games including bowls).
* Rating Scale and Spread: Generate the new rankings and check that the top team’s rating is significantly higher than before. We expect the highest rating to be > 0.013 now (was ~0.010)GitHub, and a more noticeable gap between top teams and the rest. The ratings distribution should no longer be unnaturally compressed. For example, there should be several teams (likely 4 or more from major conferences) above the 0.008 threshold, reflecting a normal spread of top 25 teamsGitHub.
* Quality Wins Populated: Inspect a few top teams (and random mid-tier teams) in the output. The “quality_wins” field should list actual opponents. No more “None” or generic top-25 placeholders – if a team beat two ranked opponents, those names should appear. For instance, a playoff-caliber team might show wins like [“Alabama”, “Georgia”] if those were their big victories. The front-end rankings page and JSON should show these entries, providing richer context.
* Correct Conference Labels: Scan the output for any “Unknown” conference entries – there should be noneGitHub. Every team should be tagged with the proper conference for that season (including Group-of-5 conferences and independents). Also, verify a few specific cases: e.g., BYU in 2023 data should show “Independent”, and in 2024 data “Big 12”; teams that changed conference in 2024 (UCLA, USC, etc.) should reflect their new conferences in 2024 outputs. This confirms the season-specific mapping is in effect.
* BYU/Big 12 Rebound: Check BYU’s new ranking and those of other Big 12 teams. They should no longer cluster abnormally low if the bowl and data issues are fixed. BYU’s rating, for example, should rise to a level commensurate with an 11–2 team with a notable bowl win (the expectation was roughly ~0.009 and a rank in the top 20GitHub). The Big 12 in aggregate should have several teams in the upper tiers if deserved, and the bias audit neutrality metric B should drop if it was high due to that previous anomaly.
All these checks can be codified into automated tests. After running the pipeline with the fixes, we should update the integration test assertions to include the above conditions (team count, top rating floor, no unknown conferences, etc.)GitHub. Passing all these tests will indicate that the data pipeline is processing clean FBS-only data, applying the correct context for games, and producing rankings that match on-field reality.
